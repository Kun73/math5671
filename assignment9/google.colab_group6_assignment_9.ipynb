{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "TDfk3Gzt9TWP",
    "outputId": "bc0bc7c7-fb95-461e-e583-08c443c3ce8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAvv4FTG_N7k"
   },
   "outputs": [],
   "source": [
    "!wget -q https://archive.apache.org/dist/spark/spark-2.2.3/spark-2.2.3-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.2.3-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "caM8YmbdDmrb",
    "outputId": "e02feabc-c244-4d7e-be6b-a8425c2f9dc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive\tsample_data  spark-2.2.3-bin-hadoop2.7\tspark-2.2.3-bin-hadoop2.7.tgz\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_xXYTfxiGJeJ",
    "outputId": "d33333f5-a03a-4c00-eff8-a0618e6e0bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"11.0.4\" 2019-07-16\n",
      "OpenJDK Runtime Environment (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3)\n",
      "OpenJDK 64-Bit Server VM (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "import os       #importing os to set environment variable\n",
    "def install_java():\n",
    "  !apt-get install -y openjdk-8-jdk-headless -qq > /dev/null      #install openjdk\n",
    "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"     #set environment variable\n",
    "  !java -version       #check java version\n",
    "install_java()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Kq1R8ND2F6ge",
    "outputId": "aea0aa14-9a73-4098-a900-daa3aeb50abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
      "\n",
      "  Selection    Path                                            Priority   Status\n",
      "------------------------------------------------------------\n",
      "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
      "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
      "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
      "\n",
      "Press <enter> to keep the current choice[*], or type selection number: 2\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
     ]
    }
   ],
   "source": [
    "!update-alternatives --config java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "js54F5paHzaO",
    "outputId": "9a5faa9f-736b-4c81-dab8-b645f63d5ec2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_222\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
      "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n"
     ]
    }
   ],
   "source": [
    "!java -version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eu_uziDuIJNM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.2.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fUTxaDIIQQ0"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFC2CNjEIRdj"
   },
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf().setAppName(\"MLlib\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "snKtdWA-IU7b",
    "outputId": "ae67b55f-4ac4-4350-a23d-4793755a688a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
      "|payment_id|customer_id|staff_id|rental_id|amount|       payment_date|        last_update|\n",
      "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
      "|         1|          1|       1|       76|  2.99|2005-05-25 11:30:37|2006-02-15 22:12:30|\n",
      "|         2|          1|       1|      573|  0.99|2005-05-28 10:35:23|2006-02-15 22:12:30|\n",
      "|         3|          1|       1|     1185|  5.99|2005-06-15 00:54:12|2006-02-15 22:12:30|\n",
      "+----------+-----------+--------+---------+------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/payment.csv')\n",
    "payment_df = payment_df.alias(\"payment_df\")\n",
    "payment_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "dencDG3xJXl9",
    "outputId": "e9959370-3a40-4803-bef5-44b83c41318c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|rental_id|        rental_date|inventory_id|customer_id|        return_date|staff_id|        last_update|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|        1|2005-05-24 22:53:30|         367|        130|2005-05-26 22:04:30|       1|2006-02-15 21:30:53|\n",
      "|        2|2005-05-24 22:54:33|        1525|        459|2005-05-28 19:40:33|       1|2006-02-15 21:30:53|\n",
      "|        3|2005-05-24 23:03:39|        1711|        408|2005-06-01 22:12:39|       1|2006-02-15 21:30:53|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/rental.csv')\n",
    "rental_df = rental_df.alias('rental_df')\n",
    "rental_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-mxoojdXNp4k",
    "outputId": "fc6bbfcf-ac7d-4176-f0dc-c63b058a9ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
      "|staff_id|first_name|last_name|address_id|picture|               email|store_id|active|username|            password|   last_update|\n",
      "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
      "|       1|      Mike|  Hillyer|         3|   NULL|Mike.Hillyer@saki...|       1|     1|    Mike|8cb2237d0679ca88d...|2/15/2006 3:57|\n",
      "|       2|       Jon| Stephens|         4|   NULL|Jon.Stephens@saki...|       2|     1|     Jon|                NULL|2/15/2006 3:57|\n",
      "+--------+----------+---------+----------+-------+--------------------+--------+------+--------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staff_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/staff.csv')\n",
    "staff_df = staff_df.alias('staff_df')\n",
    "staff_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "u9n6C0qONz8Y",
    "outputId": "43cf7b94-fc8d-42a7-c2d1-7c4cb944e0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+--------+-------------------+\n",
      "|inventory_id|film_id|store_id|        last_update|\n",
      "+------------+-------+--------+-------------------+\n",
      "|           1|      1|       1|2006-02-15 05:09:17|\n",
      "|           2|      1|       1|2006-02-15 05:09:17|\n",
      "|           3|      1|       1|2006-02-15 05:09:17|\n",
      "+------------+-------+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventory_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/inventory.csv')\n",
    "inventory_df = inventory_df.alias('inventory_df')\n",
    "inventory_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "VRX8Hk1VN23x",
    "outputId": "ef70b9ec-d2bd-478f-b3c4-831259a81f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+-------------------+\n",
      "|store_id|manager_staff_id|address_id|        last_update|\n",
      "+--------+----------------+----------+-------------------+\n",
      "|       1|               1|         1|2006-02-15 04:57:12|\n",
      "|       2|               2|         2|2006-02-15 04:57:12|\n",
      "+--------+----------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "store_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/store.csv')\n",
    "store_df = store_df.alias('store_df')\n",
    "store_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "StrbSjIBN40a",
    "outputId": "37abad6a-90ba-45f1-eb17-aa81982dafb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
      "|address_id|           address|address2|district|city_id|postal_code|      phone|        last_update|\n",
      "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
      "|         1| 47 MySakila Drive|    NULL| Alberta|    300|       null|       null|2014-09-25 22:30:27|\n",
      "|         2|28 MySQL Boulevard|    NULL|     QLD|    576|       null|       null|2014-09-25 22:30:09|\n",
      "|         3| 23 Workhaven Lane|    NULL| Alberta|    300|       null|14033335568|2014-09-25 22:30:27|\n",
      "+----------+------------------+--------+--------+-------+-----------+-----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "address_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/address.csv')\n",
    "address_df = address_df.alias('address_df')\n",
    "address_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "QiBZC10rN72j",
    "outputId": "0889ccf3-0acf-4c85-c28b-b5c770d8d1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|customer_id|store_id|first_name|last_name|               email|address_id|active|        create_date|        last_update|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "|          1|       1|      MARY|    SMITH|MARY.SMITH@sakila...|         5|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          2|       1|  PATRICIA|  JOHNSON|PATRICIA.JOHNSON@...|         6|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "|          3|       1|     LINDA| WILLIAMS|LINDA.WILLIAMS@sa...|         7|     1|2006-02-14 22:04:36|2006-02-15 04:57:20|\n",
      "+-----------+--------+----------+---------+--------------------+----------+------+-------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/customer.csv')\n",
    "customer_df = customer_df.alias('customer_df')\n",
    "customer_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "njMIvRLXN-th",
    "outputId": "f0425606-b109-4206-fdd9-270878f4e9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "|film_id|           title|         description|release_year|language_id|original_language_id|rental_duration|rental_rate|length|replacement_cost|rating|    special_features|        last_update|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "|      1|ACADEMY DINOSAUR|A Epic Drama of a...|        2006|          1|                NULL|              6|       0.99|    86|           20.99|    PG|Deleted Scenes,Be...|2006-02-15 05:03:42|\n",
      "|      2|  ACE GOLDFINGER|A Astounding Epis...|        2006|          1|                NULL|              3|       4.99|    48|           12.99|     G|Trailers,Deleted ...|2006-02-15 05:03:42|\n",
      "|      3|ADAPTATION HOLES|A Astounding Refl...|        2006|          1|                NULL|              7|       2.99|    50|           18.99| NC-17|Trailers,Deleted ...|2006-02-15 05:03:42|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'/content/gdrive/My Drive/models/rental/film.csv')\n",
    "film_df = film_df.alias('film_df')\n",
    "film_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "362NfPnsj-pH",
    "outputId": "fc08dc07-24b4-4d94-d651-0452b7cde6bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework solution start here follow by question order\n"
     ]
    }
   ],
   "source": [
    "print(\"Homework solution start here follow by question order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Bk4VNz0KRV3q",
    "outputId": "cfc09b41-3b80-4f17-8dbc-3e649da00cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|customer_id|      total_amount|\n",
      "+-----------+------------------+\n",
      "|        526| 221.5500000000001|\n",
      "|        148| 216.5400000000001|\n",
      "|        144|195.58000000000007|\n",
      "+-----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df.withColumn(\"amount\", payment_df[\"amount\"].cast(\"double\"))\n",
    "import pyspark.sql.functions as func\n",
    "#payment_df.groupby('customer_id').agg(func.sum(payment_df.amount).alias('total_amount')).orderBy('total_amount',ascending = False).show(3)\n",
    "payment_df.createOrReplaceTempView(\"payment_df\")\n",
    "spark.sql(\"select customer_id, sum(amount) as total_amount from payment_df group by customer_id order by total_amount DESC\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Ege3GwMfRW8q",
    "outputId": "408c763e-c230-424c-d71f-bfc825e8468f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|rental_id|        rental_date|inventory_id|customer_id|        return_date|staff_id|        last_update|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "|       32|2005-05-25 04:06:21|        3832|        230|2005-05-25 23:55:21|       1|2006-02-15 21:30:53|\n",
      "|       21|2005-05-25 01:59:46|         146|        388|2005-05-26 01:01:46|       2|2006-02-15 21:30:53|\n",
      "|       14|2005-05-25 00:31:15|        2701|        446|2005-05-26 02:56:15|       1|2006-02-15 21:30:53|\n",
      "+---------+-------------------+------------+-----------+-------------------+--------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_df.createOrReplaceTempView(\"rental_df\")\n",
    "spark.sql(\"select * from rental_df where year(rental_date) = 2005 order by return_date\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Z6meL5GYRnzk",
    "outputId": "825c3a29-812d-44ec-d967-59785b338183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|staff_id|count|\n",
      "+--------+-----+\n",
      "|       1| 8040|\n",
      "|       2| 8004|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select staff_id, count(rental_id) as count from rental_df group by staff_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "8c9FIdBMRceY",
    "outputId": "05d44dc1-5569-438e-d27b-0f418690248b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|first_name|last_name|count|\n",
      "+----------+---------+-----+\n",
      "|      Mike|  Hillyer| 8040|\n",
      "|       Jon| Stephens| 8004|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staff_df.createOrReplaceTempView(\"staff_df\")\n",
    "spark.sql(\"select first(first_name) as first_name, first(last_name) as last_name, count(rental_id) as count from staff_df inner join rental_df on rental_df.staff_id = staff_df.staff_id group by staff_df.staff_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "lRPeTflsjyLP",
    "outputId": "ff807a65-37b6-40eb-8c1f-47ef67002a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+---------------+--------------------+----------+---------+----------+---------+\n",
      "|        rental_date|        return_date|           address|          title|         description|first_name|last_name|first_name|last_name|\n",
      "+-------------------+-------------------+------------------+---------------+--------------------+----------+---------+----------+---------+\n",
      "|2005-05-24 22:53:30|2005-05-26 22:04:30| 47 MySakila Drive|BLANKET BEVERLY|A Emotional Docum...| CHARLOTTE|   HUNTER|      Mike|  Hillyer|\n",
      "|2005-05-24 22:54:33|2005-05-28 19:40:33|28 MySQL Boulevard|   FREAKY POCUS|A Fast-Paced Docu...|     TOMMY|  COLLAZO|      Mike|  Hillyer|\n",
      "|2005-05-24 23:03:39|2005-06-01 22:12:39|28 MySQL Boulevard|  GRADUATE LORD|A Lacklusture Epi...|    MANUEL|  MURRELL|      Mike|  Hillyer|\n",
      "+-------------------+-------------------+------------------+---------------+--------------------+----------+---------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventory_df.createOrReplaceTempView(\"inventory_df\")\n",
    "store_df.createOrReplaceTempView(\"store_df\")\n",
    "address_df.createOrReplaceTempView(\"address_df\")\n",
    "customer_df.createOrReplaceTempView(\"customer_df\")\n",
    "film_df.createOrReplaceTempView(\"film_df\")\n",
    "spark.sql(\"\"\"select r.rental_date, r.return_date, a.address, f.title, f.description, c.first_name, c.last_name, s.first_name, s.last_name\n",
    "from rental_df as r\n",
    "join inventory_df as i\n",
    "on r.inventory_id = i.inventory_id\n",
    "join store_df as st\n",
    "on i.store_id = st.store_id\n",
    "join address_df as a\n",
    "on st.address_id = a.address_id\n",
    "join customer_df as c\n",
    "on r.customer_id = c.customer_id\n",
    "join staff_df as s\n",
    "on s.store_id = c.store_id\n",
    "join film_df as f\n",
    "on i.film_id = f.film_id\n",
    "order by r.rental_date\n",
    " \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "wJLYMtYaRfg2",
    "outputId": "310dbbe8-a795-4c8e-85a8-17d8f636955e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|customer_id|     total_amount|\n",
      "+-----------+-----------------+\n",
      "|        526|221.5500000000001|\n",
      "|        148|216.5400000000001|\n",
      "+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select customer_id, total_amount from\n",
    "(select customer_id, sum(amount) as total_amount from payment_df where year(payment_date) =2005 group by customer_id)\n",
    "where total_amount > 200\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "MCqkNaeXZ9nY",
    "outputId": "542d5746-aeec-4849-ec39-456c7a2cad49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+\n",
      "|first_name|last_name|     total_amount|\n",
      "+----------+---------+-----------------+\n",
      "|      KARL|     SEAL|221.5500000000001|\n",
      "|   ELEANOR|     HUNT|216.5400000000001|\n",
      "+----------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.createOrReplaceTempView(\"customer_df\")\n",
    "spark.sql(\"\"\"select * from\n",
    "(select first(customer_df.first_name) as first_name, first(customer_df.last_name) as last_name, sum(amount) as total_amount from payment_df\n",
    "inner join customer_df\n",
    "on customer_df.customer_id = payment_df.customer_id where year(payment_date) =2005 group by payment_df.customer_id)\n",
    "where total_amount > 200 \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "zcgUzHxyd8_v",
    "outputId": "4b8f5be1-36ec-41ab-87ff-00029b7bc062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------+\n",
      "|customer_id_in_2005_not_in_2006|rentyear|\n",
      "+-------------------------------+--------+\n",
      "|                            413|    2005|\n",
      "|                            377|    2005|\n",
      "|                            406|    2005|\n",
      "|                            148|    2005|\n",
      "|                            463|    2005|\n",
      "|                             26|    2005|\n",
      "|                            358|    2005|\n",
      "|                             62|    2005|\n",
      "|                            285|    2005|\n",
      "|                            392|    2005|\n",
      "+-------------------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------------------------+\n",
      "|customer_id_in_2005_not_in_2006|\n",
      "+-------------------------------+\n",
      "|                            441|\n",
      "+-------------------------------+\n",
      "\n",
      "+-------------------------------+--------+\n",
      "|customer_id_in_2006_not_in_2005|rentyear|\n",
      "+-------------------------------+--------+\n",
      "+-------------------------------+--------+\n",
      "\n",
      "+-------------------------------+\n",
      "|customer_id_in_2006_not_in_2005|\n",
      "+-------------------------------+\n",
      "|                              0|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c2005 = spark.sql(\"select customer_id, year(rental_date) as rentyear from rental_df where year(rental_date) = 2005\")\n",
    "c2006 = spark.sql(\"select customer_id, year(rental_date) as rentyear from rental_df where year(rental_date) = 2006\")\n",
    "c2005.createOrReplaceTempView(\"c2005\")\n",
    "c2006.createOrReplaceTempView(\"c2006\")\n",
    "spark.sql(\"\"\"select distinct(c2005.customer_id) as customer_id_in_2005_not_in_2006, c2005.rentyear from c2005\n",
    "where c2005.customer_id not in (\n",
    "    select c2006.customer_id from c2006\n",
    ") \"\"\").show(10)\n",
    "spark.sql(\"\"\"select count(distinct(c2005.customer_id)) as customer_id_in_2005_not_in_2006 from c2005\n",
    "where c2005.customer_id not in (\n",
    "    select c2006.customer_id from c2006\n",
    ") \"\"\").show()\n",
    "spark.sql(\"\"\"select distinct(c2006.customer_id) as customer_id_in_2006_not_in_2005, c2006.rentyear from c2006\n",
    "where c2006.customer_id not in (\n",
    "    select c2005.customer_id from c2005\n",
    ") \"\"\").show(10)\n",
    "spark.sql(\"\"\"select count(c2006.customer_id) as customer_id_in_2006_not_in_2005 from c2006\n",
    "where c2006.customer_id not in (\n",
    "    select c2005.customer_id from c2005\n",
    ") \"\"\").show(10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
