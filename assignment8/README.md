# RDD using pyspark

When using **pyspark**, Java 8 is required. Before we specify the `SparkContext()`, we may initialize the directory of Java8. 

For the given data set, we first delete its header, and then use RDD to print records. For the double quotes, we preprocess them using EXCEL.  

You can preview [here](https://nbviewer.jupyter.org/github/Kun73/math5671/blob/master/assignment8/group_6_assignment8.ipynb)
